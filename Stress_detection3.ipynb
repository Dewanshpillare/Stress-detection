{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eoNwIgPR1w2"
   },
   "source": [
    "FINDING THE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9HbvxeHscZn",
    "outputId": "3dc42ef9-555a-4059-da52-04c1971bf4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/WESAD.zip\n"
     ]
    }
   ],
   "source": [
    "#find path\n",
    "!ls '/content/drive/MyDrive/WESAD.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsWaYa_pR_MI"
   },
   "source": [
    "EXTRACT THE DATA FROM ZIP FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSTqn2a3s8bd",
    "outputId": "20009e68-d1e0-4f64-c3a0-229cb793ac42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# extracting the data and storing it in temprory storage of colab\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Define the path to your zip file\n",
    "zip_file_path = '/content/drive/MyDrive/WESAD.zip' #path from where you want to extract the data\n",
    "extract_path = '/content/WESAD/'  # Path where you want to extract files\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mumbk7SSSvlA"
   },
   "source": [
    "Certainly! Here’s an explanation of the code in a step-by-step flow of control:\n",
    "\n",
    "1. **Define the List of Subject File Paths**:\n",
    "   - We start by creating a list of file paths for each subject’s data, which are `.pkl` files containing the WESAD dataset for individual subjects. Each path corresponds to a separate subject.\n",
    "\n",
    "2. **Initialize Storage Lists**:\n",
    "   - `all_data` and `all_labels` lists are created to store processed sensor data and corresponding labels from each subject.\n",
    "\n",
    "3. **Initialize Label Encoder**:\n",
    "   - `LabelEncoder` is initialized to convert categorical labels into numerical values later.\n",
    "\n",
    "4. **Loop Through Each Subject’s Data File**:\n",
    "   - For each subject’s file in `subject_files`, the following steps are performed.\n",
    "\n",
    "5. **Load the Subject Data**:\n",
    "   - Each `.pkl` file is loaded into a DataFrame called `subject_data`.\n",
    "\n",
    "6. **Access Wrist Signal Data**:\n",
    "   - The code extracts wrist signal data from the dataset and stores it in `signal_data`.\n",
    "\n",
    "7. **Extract Specific Wrist Signals (BVP, EDA, TEMP)**:\n",
    "   - BVP (Blood Volume Pulse), EDA (Electrodermal Activity), and TEMP (Temperature) signals are extracted and stored in a dictionary called `body_data`.\n",
    "\n",
    "8. **Determine Minimum Length for Consistent Downsampling**:\n",
    "   - The minimum length among the BVP, EDA, and TEMP signals is calculated. This ensures each signal has the same length before downsampling.\n",
    "\n",
    "9. **Truncate Each Signal to Minimum Length**:\n",
    "   - Each signal (BVP, EDA, and TEMP) is truncated to the minimum length to ensure consistency across all signals.\n",
    "\n",
    "10. **Set Downsampling Factor**:\n",
    "   - A downsampling factor (5 in this case) is defined, controlling the number of data points to combine in each downsampling step.\n",
    "\n",
    "11. **Downsample and Calculate Statistics**:\n",
    "    - For each signal (BVP, EDA, and TEMP):\n",
    "      - The signal is reshaped to groups based on the `downsampling_factor`.\n",
    "      - **Mean**, **Standard Deviation (std)**, and **Maximum (max)** are calculated across each downsampled segment.\n",
    "      - These statistics (`mean`, `std`, `max`) are added to `body_data`, replacing the original signals.\n",
    "\n",
    "12. **Convert Processed Data to a DataFrame**:\n",
    "    - The downsampled and processed data in `body_data` is converted to a DataFrame called `body_df`.\n",
    "\n",
    "13. **Normalize the Data**:\n",
    "    - The `MinMaxScaler` scales the data in `body_df` to a range between 0 and 1, and the normalized data is stored in `normalized_df`.\n",
    "\n",
    "14. **Append Normalized Data to `all_data` List**:\n",
    "    - The normalized DataFrame (`normalized_df`) is added to the `all_data` list for later concatenation.\n",
    "\n",
    "15. **Extract and Append Labels**:\n",
    "    - Labels from each subject are extracted, flattened, and appended to `all_labels`.\n",
    "\n",
    "16. **Combine All Subjects’ Data and Labels**:\n",
    "    - After processing all subjects, data in `all_data` is combined into a single DataFrame called `combined_data`.\n",
    "    - Similarly, all labels in `all_labels` are concatenated into a single array called `combined_labels`.\n",
    "\n",
    "17. **Convert Multi-Level Labels to Binary Labels**:\n",
    "    - Labels are converted to binary values where all occurrences of label `2` are relabeled as `1` for binary classification.\n",
    "\n",
    "18. **Adjust Label Array to Match Data Length**:\n",
    "    - If the length of `combined_labels` is greater than `combined_data`, labels are downsampled using majority voting (`mode`).\n",
    "    - This ensures the label array matches the length of the data array.\n",
    "    - If the labels are shorter than the data, a warning is printed.\n",
    "\n",
    "19. **Encode Labels**:\n",
    "    - Labels are encoded as `0` and `1` using `LabelEncoder` for binary classification.\n",
    "\n",
    "20. **Print Summary of Data and Labels**:\n",
    "    - The shapes of `combined_data` and `encoded_labels` are printed, along with a sample of the labels and label distribution, to confirm that the data processing is complete.\n",
    "\n",
    "This step-by-step process ensures that the wrist data is uniformly processed, downsampled, normalized, and encoded for use in a CNN model tailored for stress detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyUOEZeGuOUK",
    "outputId": "1b547b51-db3a-4874-8c0d-c3bfdd085054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape: (69487, 9)\n",
      "Encoded Labels Shape: (69487,)\n",
      "Encoded Labels Sample: [0 0 0 0 0 0 0 0 0 0]\n",
      "New Label Distribution: {0: 31598, 1: 22060, 2: 4464, 3: 9444, 4: 633, 5: 632, 6: 656}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "\n",
    "# List of subject file paths\n",
    "subject_files = [\n",
    "    '/content/WESAD/WESAD/S2/S2.pkl',\n",
    "    '/content/WESAD/WESAD/S3/S3.pkl',\n",
    "    '/content/WESAD/WESAD/S4/S4.pkl',\n",
    "    '/content/WESAD/WESAD/S5/S5.pkl',\n",
    "    '/content/WESAD/WESAD/S6/S6.pkl',\n",
    "    '/content/WESAD/WESAD/S7/S7.pkl',\n",
    "    '/content/WESAD/WESAD/S8/S8.pkl',\n",
    "    '/content/WESAD/WESAD/S9/S9.pkl',\n",
    "    '/content/WESAD/WESAD/S10/S10.pkl',\n",
    "    '/content/WESAD/WESAD/S11/S11.pkl',\n",
    "    '/content/WESAD/WESAD/S13/S13.pkl',\n",
    "    '/content/WESAD/WESAD/S14/S14.pkl',\n",
    "    '/content/WESAD/WESAD/S15/S15.pkl',\n",
    "    '/content/WESAD/WESAD/S16/S16.pkl',\n",
    "    '/content/WESAD/WESAD/S17/S17.pkl'\n",
    "]\n",
    "\n",
    "# Initialize empty lists to store data and labels\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "# Initialize LabelEncoder for labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Process each subject's data\n",
    "for file_path in subject_files:\n",
    "    # Load data for each subject\n",
    "    subject_data = pd.read_pickle(file_path)\n",
    "\n",
    "    # Access wrist signal data\n",
    "    signal_data = subject_data['signal']['wrist']\n",
    "\n",
    "    # Extract wrist signals (BVP, EDA, TEMP)\n",
    "    body_data = {\n",
    "        'bvp': signal_data['BVP'].flatten(),\n",
    "        'eda': signal_data['EDA'].flatten(),\n",
    "        'temperature': signal_data['TEMP'].flatten()\n",
    "    }\n",
    "\n",
    "    # Determine the minimum length of the signals for consistent downsampling\n",
    "    min_length = min(len(body_data['bvp']), len(body_data['eda']), len(body_data['temperature']))\n",
    "\n",
    "    # Truncate each signal to the minimum length\n",
    "    for signal in ['bvp', 'eda', 'temperature']:\n",
    "        body_data[signal] = body_data[signal][:min_length]\n",
    "\n",
    "    # Define downsampling factor (e.g., 5)\n",
    "    downsampling_factor = 5  # Adjust this as needed for balancing detail and processing\n",
    "\n",
    "    # Downsample and calculate statistics (mean, std, max) for each signal\n",
    "    for signal in ['bvp', 'eda', 'temperature']:\n",
    "        signal_values = body_data[signal]\n",
    "        downsampled_length = min_length // downsampling_factor\n",
    "\n",
    "        # Reshape for downsampling (this should prevent zeros in std calculation)\n",
    "        reshaped_signal = signal_values[:downsampled_length * downsampling_factor].reshape(-1, downsampling_factor)\n",
    "\n",
    "        # Calculate mean, std, and max across each downsampled segment\n",
    "        mean_values = np.mean(reshaped_signal, axis=1)\n",
    "        std_values = np.std(reshaped_signal, axis=1)\n",
    "        max_values = np.max(reshaped_signal, axis=1)\n",
    "\n",
    "        # Add the calculated statistics to the data dictionary\n",
    "        body_data[f'{signal}_mean'] = mean_values\n",
    "        body_data[f'{signal}_std'] = std_values\n",
    "        body_data[f'{signal}_max'] = max_values\n",
    "\n",
    "        # Remove original signal data to avoid redundancy\n",
    "        del body_data[signal]\n",
    "\n",
    "    # Convert processed data into a DataFrame\n",
    "    body_df = pd.DataFrame(body_data)\n",
    "\n",
    "    # Normalize the sensor data\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(body_df)\n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=body_df.columns)\n",
    "\n",
    "    # Append normalized data\n",
    "    all_data.append(normalized_df)\n",
    "\n",
    "    # Extract and append labels for each subject\n",
    "    labels = subject_data['label'].flatten()\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Combine data and labels across all subjects\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "combined_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Convert multi-level labels (e.g., stress levels) to binary classification if needed\n",
    "combined_labels = np.where(combined_labels == 2, 1, combined_labels)\n",
    "\n",
    "# Adjust label array to match combined data length\n",
    "desired_length = len(combined_data)\n",
    "if len(combined_labels) > desired_length:\n",
    "    # Downsample combined_labels using mode (majority voting)\n",
    "    ratio = len(combined_labels) // desired_length\n",
    "    combined_labels = [\n",
    "        mode(combined_labels[min(i * ratio, len(combined_labels) - 1):min((i + 1) * ratio, len(combined_labels))]).mode[0]\n",
    "        if len(combined_labels[min(i * ratio, len(combined_labels) - 1):min((i + 1) * ratio, len(combined_labels))]) > 0 and isinstance(mode(combined_labels[min(i * ratio, len(combined_labels) - 1):min((i + 1) * ratio, len(combined_labels))]).mode, np.ndarray)\n",
    "        else combined_labels[min(i * ratio, len(combined_labels) - 1)]\n",
    "        for i in range(desired_length)\n",
    "    ]\n",
    "elif len(combined_labels) < desired_length:\n",
    "    print(\"Warning: The number of combined labels is less than the number of combined data rows.\")\n",
    "\n",
    "# Check processed data shapes and distributions\n",
    "print(\"Combined Data Shape:\", combined_data.shape)\n",
    "print(\"Encoded Labels Shape:\", encoded_labels.shape)\n",
    "print(\"Encoded Labels Sample:\", encoded_labels[:10])\n",
    "print(\"New Label Distribution:\", {i: np.sum(encoded_labels == i) for i in np.unique(encoded_labels)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CgKGPfKTB7a"
   },
   "source": [
    "Checking for duplicate rows and basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "if6hX0h886uz",
    "outputId": "11ff9466-36da-4b8d-f58d-59978347fa03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Total Null Values in Each Column:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Basic Statistics:\n",
      "            bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.521660      0.055586      0.496505      0.235844      0.023337   \n",
      "std        0.099959      0.077850      0.096481      0.231481      0.057822   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000  \n",
      "mean       0.227349          0.576014         0.164043         0.575788  \n",
      "std        0.231760          0.298540         0.171458         0.299041  \n",
      "min        0.000000          0.000000         0.000000         0.000000  \n",
      "25%        0.061389          0.310987         0.000000         0.308880  \n",
      "50%        0.136029          0.632216         0.163299         0.631579  \n",
      "75%        0.308031          0.846154         0.285714         0.846154  \n",
      "max        1.000000          1.000000         1.000000         1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming combined_data is your DataFrame\n",
    "# Check for duplicates\n",
    "duplicate_rows = combined_data[combined_data.duplicated()]\n",
    "num_duplicates = duplicate_rows.shape[0]\n",
    "\n",
    "# Check for null values\n",
    "null_values = combined_data.isnull().sum()\n",
    "total_nulls = null_values[null_values > 0]\n",
    "\n",
    "# Get basic statistics\n",
    "statistics = combined_data.describe()\n",
    "\n",
    "# Print results\n",
    "print(\"Number of Duplicate Rows:\", num_duplicates)\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\nDuplicate Rows:\\n\", duplicate_rows)\n",
    "\n",
    "print(\"\\nTotal Null Values in Each Column:\\n\", total_nulls)\n",
    "\n",
    "print(\"\\nBasic Statistics:\\n\", statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltgcHNuKTOkp"
   },
   "source": [
    "Viewing combined data once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIoQvhR8D26r",
    "outputId": "1014faf7-fafa-4cb1-f495-f56418529b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of Combined Data:\n",
      "   bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "0  0.432751  0.081647  0.403546  0.611997  0.150707  0.649919   \n",
      "1  0.483221  0.080188  0.452608  0.568807  0.118939  0.623526   \n",
      "2  0.509877  0.018219  0.466198  0.736725  0.089108  0.746674   \n",
      "3  0.511898  0.001696  0.465986  0.748934  0.052465  0.750546   \n",
      "4  0.511151  0.001481  0.465021  0.693120  0.036978  0.692458   \n",
      "\n",
      "   temperature_mean  temperature_std  temperature_max  \n",
      "0          0.848684            0.000         0.846154  \n",
      "1          0.848684            0.000         0.846154  \n",
      "2          0.848684            0.000         0.846154  \n",
      "3          0.853070            0.125         0.851648  \n",
      "4          0.849781            0.125         0.851648  \n",
      "\n",
      "DataFrame Structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69487 entries, 0 to 69486\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   bvp_mean          69487 non-null  float64\n",
      " 1   bvp_std           69487 non-null  float64\n",
      " 2   bvp_max           69487 non-null  float64\n",
      " 3   eda_mean          69487 non-null  float64\n",
      " 4   eda_std           69487 non-null  float64\n",
      " 5   eda_max           69487 non-null  float64\n",
      " 6   temperature_mean  69487 non-null  float64\n",
      " 7   temperature_std   69487 non-null  float64\n",
      " 8   temperature_max   69487 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 4.8 MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "           bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.521660      0.055586      0.496505      0.235844      0.023337   \n",
      "std        0.099959      0.077850      0.096481      0.231481      0.057822   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000  \n",
      "mean       0.227349          0.576014         0.164043         0.575788  \n",
      "std        0.231760          0.298540         0.171458         0.299041  \n",
      "min        0.000000          0.000000         0.000000         0.000000  \n",
      "25%        0.061389          0.310987         0.000000         0.308880  \n",
      "50%        0.136029          0.632216         0.163299         0.631579  \n",
      "75%        0.308031          0.846154         0.285714         0.846154  \n",
      "max        1.000000          1.000000         1.000000         1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming combined_data is your DataFrame\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(\"First 5 Rows of Combined Data:\")\n",
    "print(combined_data.head())\n",
    "\n",
    "# Display the structure of the DataFrame\n",
    "print(\"\\nDataFrame Structure:\")\n",
    "print(combined_data.info())\n",
    "\n",
    "# Optionally, you can display summary statistics for numerical columns\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(combined_data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Anm4BexVTY8s"
   },
   "source": [
    "Viewing one of the pkl files for checking number of lables in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5iwru7hTqWo"
   },
   "source": [
    "viewing unique lables in .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGDx2C-aPzmT",
    "outputId": "3ff65f34-e2ef-47ba-da58-db7277a0b82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels in S2.pkl: [0 1 2 6 4 3 7]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the S2.pkl file\n",
    "file_path = '/content/WESAD/WESAD/S2/S2.pkl'\n",
    "subject_data = pd.read_pickle(file_path)\n",
    "\n",
    "# Access the labels\n",
    "labels = subject_data['label']\n",
    "\n",
    "# Get unique values of the labels\n",
    "unique_labels = pd.unique(labels)\n",
    "\n",
    "# Display the unique labels\n",
    "print(\"Unique Labels in S2.pkl:\", unique_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCuxrpoBTvAt"
   },
   "source": [
    "combining the lables 1 - 7 as single lable 1 so that we can balance the classes of unstressed and stressed. Because Unstressed class have lot of data compared to each labled stress class. And we have to perform binary classification, so two lables 0 and 1 are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvU3pzq9RJbd",
    "outputId": "fe52e493-d188-4037-e83b-82aee8b78c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Label Distribution: {0: 31598, 1: 37889}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample labels array for demonstration; replace this with your actual labels array\n",
    "# combined_labels = np.array([...])  # Assuming you already have the combined labels in a NumPy array\n",
    "\n",
    "# If your labels are in a DataFrame, you can use:\n",
    "# combined_labels = your_dataframe['your_label_column'].to_numpy()\n",
    "\n",
    "# Combine labels 1 to 7 into a single class labeled as 1\n",
    "combined_labels = np.where(np.isin(combined_labels, [1, 2, 3, 4, 5, 6, 7]), 1, combined_labels)\n",
    "\n",
    "# Verify the changes\n",
    "new_label_distribution = {i: np.sum(combined_labels == i) for i in np.unique(combined_labels)}\n",
    "\n",
    "# Output the new label distribution\n",
    "print(\"New Label Distribution:\", new_label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vS7oJZfGeEr9",
    "outputId": "d6f077dc-07a9-44d8-e09c-2f319d18f468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame Preview:\n",
      "    bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "0  0.432751  0.081647  0.403546  0.611997  0.150707  0.649919   \n",
      "1  0.483221  0.080188  0.452608  0.568807  0.118939  0.623526   \n",
      "2  0.509877  0.018219  0.466198  0.736725  0.089108  0.746674   \n",
      "3  0.511898  0.001696  0.465986  0.748934  0.052465  0.750546   \n",
      "4  0.511151  0.001481  0.465021  0.693120  0.036978  0.692458   \n",
      "\n",
      "   temperature_mean  temperature_std  temperature_max  Labels  \n",
      "0          0.848684            0.000         0.846154       0  \n",
      "1          0.848684            0.000         0.846154       0  \n",
      "2          0.848684            0.000         0.846154       0  \n",
      "3          0.853070            0.125         0.851648       0  \n",
      "4          0.849781            0.125         0.851648       0  \n",
      "Shape of Combined DataFrame: (69487, 10)\n",
      "Missing Values in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "Labels              0\n",
      "dtype: int64\n",
      "Label Distribution:\n",
      " Labels\n",
      "0    31598\n",
      "1    22060\n",
      "3     9444\n",
      "2     4464\n",
      "6      656\n",
      "4      633\n",
      "5      632\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming combined_data contains the features and encoded_labels contains the new labels\n",
    "# combined_data should be a DataFrame containing columns for BVP, EDA, and Temperature\n",
    "\n",
    "# Ensure both combined_data and encoded_labels are the same length\n",
    "assert len(combined_data) == len(encoded_labels), \"Data and labels must be of the same length\"\n",
    "\n",
    "# Combine the processed data and the labels into a single DataFrame\n",
    "# Assuming combined_data is your existing DataFrame that contains the processed features\n",
    "combined_df = pd.DataFrame(combined_data)  # Use combined_data directly\n",
    "combined_df['Labels'] = encoded_labels  # Add the new labels as a column\n",
    "\n",
    "# Check the combined DataFrame\n",
    "print(\"Combined DataFrame Preview:\\n\", combined_df.head())\n",
    "print(\"Shape of Combined DataFrame:\", combined_df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = combined_df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
    "\n",
    "# Check the distribution of labels to ensure synchronization\n",
    "label_distribution = combined_df['Labels'].value_counts()\n",
    "print(\"Label Distribution:\\n\", label_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdWZzU73WuWD"
   },
   "source": [
    "**Checking data Quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MhLET_Wenl-",
    "outputId": "3c656328-42db-4400-f5a2-74fe5c95f4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "Labels              0\n",
      "dtype: int64\n",
      "\n",
      "Data Types in Combined DataFrame:\n",
      " bvp_mean            float64\n",
      "bvp_std             float64\n",
      "bvp_max             float64\n",
      "eda_mean            float64\n",
      "eda_std             float64\n",
      "eda_max             float64\n",
      "temperature_mean    float64\n",
      "temperature_std     float64\n",
      "temperature_max     float64\n",
      "Labels                int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "            bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.521660      0.055586      0.496505      0.235844      0.023337   \n",
      "std        0.099959      0.077850      0.096481      0.231481      0.057822   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \\\n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000   \n",
      "mean       0.227349          0.576014         0.164043         0.575788   \n",
      "std        0.231760          0.298540         0.171458         0.299041   \n",
      "min        0.000000          0.000000         0.000000         0.000000   \n",
      "25%        0.061389          0.310987         0.000000         0.308880   \n",
      "50%        0.136029          0.632216         0.163299         0.631579   \n",
      "75%        0.308031          0.846154         0.285714         0.846154   \n",
      "max        1.000000          1.000000         1.000000         1.000000   \n",
      "\n",
      "             Labels  \n",
      "count  69487.000000  \n",
      "mean       0.992243  \n",
      "std        1.235356  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        6.000000  \n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Label Distribution:\n",
      " Labels\n",
      "0    31598\n",
      "1    22060\n",
      "3     9444\n",
      "2     4464\n",
      "6      656\n",
      "4      633\n",
      "5      632\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outliers in Each Column:\n",
      " bvp_mean    1159\n",
      "bvp_std     5806\n",
      "eda_mean    5492\n",
      "dtype: int64\n",
      "\n",
      "Value Counts for bvp_mean:\n",
      " bvp_mean\n",
      "0.000000    15\n",
      "1.000000     9\n",
      "0.547619     4\n",
      "0.465647     4\n",
      "0.694506     4\n",
      "            ..\n",
      "0.576486     1\n",
      "0.628611     1\n",
      "0.652508     1\n",
      "0.656021     1\n",
      "0.473693     1\n",
      "Name: count, Length: 66511, dtype: int64\n",
      "\n",
      "Value Counts for bvp_std:\n",
      " bvp_std\n",
      "0.000000    15\n",
      "1.000000     8\n",
      "1.000000     7\n",
      "0.008428     2\n",
      "0.003649     2\n",
      "            ..\n",
      "0.027833     1\n",
      "0.012101     1\n",
      "0.019438     1\n",
      "0.005589     1\n",
      "0.055464     1\n",
      "Name: count, Length: 69435, dtype: int64\n",
      "\n",
      "Value Counts for eda_mean:\n",
      " eda_mean\n",
      "0.176671    43\n",
      "0.179225    37\n",
      "0.178373    33\n",
      "0.165602    31\n",
      "0.175819    31\n",
      "            ..\n",
      "0.129389     1\n",
      "0.128266     1\n",
      "0.127277     1\n",
      "0.126261     1\n",
      "0.006741     1\n",
      "Name: count, Length: 52052, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = combined_df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
    "\n",
    "# Check data types of each column\n",
    "data_types = combined_df.dtypes\n",
    "print(\"\\nData Types in Combined DataFrame:\\n\", data_types)\n",
    "\n",
    "# Get summary statistics for the numeric columns\n",
    "summary_statistics = combined_df.describe()\n",
    "print(\"\\nSummary Statistics:\\n\", summary_statistics)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = combined_df.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows)\n",
    "\n",
    "# Check label distribution\n",
    "label_distribution = combined_df['Labels'].value_counts()\n",
    "print(\"\\nLabel Distribution:\\n\", label_distribution)\n",
    "\n",
    "# Additional quality checks (optional)\n",
    "# Check for outliers using Interquartile Range (IQR)\n",
    "# Adjust the columns as per your current DataFrame\n",
    "# Replace with your actual numeric column names from combined_df\n",
    "numeric_columns = ['bvp_mean', 'bvp_std', 'eda_mean']  # Example: Replace with your actual column names\n",
    "Q1 = combined_df[numeric_columns].quantile(0.25)\n",
    "Q3 = combined_df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_condition = ((combined_df[numeric_columns] < (Q1 - 1.5 * IQR)) | (combined_df[numeric_columns] > (Q3 + 1.5 * IQR)))\n",
    "outliers = outlier_condition.sum()\n",
    "print(\"\\nOutliers in Each Column:\\n\", outliers)\n",
    "\n",
    "# Optional: Check for any specific value counts for BVP, EDA, and Temperature\n",
    "for col in numeric_columns:\n",
    "    value_counts = combined_df[col].value_counts()\n",
    "    print(f\"\\nValue Counts for {col}:\\n\", value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHsbQvJrhutW",
    "outputId": "637fd494-6202-4c3d-b0f7-6c63c2f61411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined DataFrame after removing duplicates: (69487, 10)\n",
      "Combined DataFrame Preview:\n",
      "   bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "0  0.432751  0.081647  0.403546  0.611997  0.150707  0.649919   \n",
      "1  0.483221  0.080188  0.452608  0.568807  0.118939  0.623526   \n",
      "2  0.509877  0.018219  0.466198  0.736725  0.089108  0.746674   \n",
      "3  0.511898  0.001696  0.465986  0.748934  0.052465  0.750546   \n",
      "4  0.511151  0.001481  0.465021  0.693120  0.036978  0.692458   \n",
      "\n",
      "   temperature_mean  temperature_std  temperature_max  Labels  \n",
      "0          0.848684            0.000         0.846154       0  \n",
      "1          0.848684            0.000         0.846154       0  \n",
      "2          0.848684            0.000         0.846154       0  \n",
      "3          0.853070            0.125         0.851648       0  \n",
      "4          0.849781            0.125         0.851648       0  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from the combined DataFrame\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# Check the shape of the DataFrame after removing duplicates\n",
    "print(\"Shape of combined DataFrame after removing duplicates:\", combined_df.shape)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "print(\"Combined DataFrame Preview:\")\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZHwso8FWfQp"
   },
   "source": [
    "box plot to check outliners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "QHJbiRKKXGWZ",
    "outputId": "824e7c40-8038-45e4-9dc7-286a794fd2fe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create box plots for each sensor\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(y=combined_df['bvp_mean'])\n",
    "plt.title('BVP Mean')\n",
    "plt.ylabel('BVP Values')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(y=combined_df['eda_mean'])\n",
    "plt.title('EDA Mean')\n",
    "plt.ylabel('EDA Values')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y=combined_df['temperature_mean'])\n",
    "plt.title('Temperature Mean')\n",
    "plt.ylabel('Temperature Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOmjkv9IUvQX",
    "outputId": "1a1e46e7-caa0-46be-bdaf-0c1ada8df9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
      "       'temperature_mean', 'temperature_std', 'temperature_max', 'Labels'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names in combined_df\n",
    "print(combined_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lw1ryF4lRIDe",
    "outputId": "80e6611f-cd5d-485a-fe22-f96d07cbd9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Combined DataFrame Preview:\n",
      "    bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "0  0.432751  0.081647  0.403546  0.611997  0.150707  0.649919   \n",
      "1  0.483221  0.080188  0.452608  0.568807  0.118939  0.623526   \n",
      "2  0.509877  0.018219  0.466198  0.736725  0.089108  0.746674   \n",
      "3  0.511898  0.001696  0.465986  0.748934  0.052465  0.750546   \n",
      "4  0.511151  0.001481  0.465021  0.693120  0.036978  0.692458   \n",
      "\n",
      "   temperature_mean  temperature_std  temperature_max  Labels  \n",
      "0          0.848684            0.000         0.846154       0  \n",
      "1          0.848684            0.000         0.846154       0  \n",
      "2          0.848684            0.000         0.846154       0  \n",
      "3          0.853070            0.125         0.851648       0  \n",
      "4          0.849781            0.125         0.851648       0  \n",
      "New Label Distribution:\n",
      " Labels\n",
      "1    37889\n",
      "0    31598\n",
      "Name: count, dtype: int64\n",
      "Unique Labels and Their Counts:\n",
      " Labels\n",
      "1    37889\n",
      "0    31598\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Relabel 1 to 5 as 1 in the 'Labels' column\n",
    "combined_df['Labels'] = combined_df['Labels'].replace([1, 2, 3, 4, 5, 6], 1)\n",
    "\n",
    "# Check the updated combined_df\n",
    "print(\"Updated Combined DataFrame Preview:\\n\", combined_df.head())\n",
    "\n",
    "# Check the new label distribution to verify the changes\n",
    "new_label_distribution = combined_df['Labels'].value_counts()\n",
    "print(\"New Label Distribution:\\n\", new_label_distribution)\n",
    "\n",
    "# Check for unique labels and their counts in the 'Labels' column\n",
    "unique_labels_counts = combined_df['Labels'].value_counts()\n",
    "\n",
    "# Display the unique labels and their counts\n",
    "print(\"Unique Labels and Their Counts:\\n\", unique_labels_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxOGnfvcMdAc"
   },
   "source": [
    "Handeling the Outliners\n",
    "Step 1 - find lower and  higher whisker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeyS8OBIWS4f"
   },
   "source": [
    "Code to Handle Outliers by Capping and Adding Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiIqUAFzM9z5",
    "outputId": "605865de-44b9-4a3c-ec6a-2a2937d729b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier values have been capped and modified.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming combined_df is your DataFrame\n",
    "# Step 1: Calculate Q1, Q3, and IQR for each relevant column\n",
    "Q1 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.25)\n",
    "Q3 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Step 2: Define bounds for outlier detection\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Step 3: Cap outliers and add variation\n",
    "def cap_outliers(series, lower, upper):\n",
    "    # Cap lower outliers\n",
    "    series = np.where(series < lower, lower + np.random.uniform(0, 0.1 * (upper - lower), size=series.shape), series)\n",
    "    # Cap upper outliers\n",
    "    series = np.where(series > upper, upper - np.random.uniform(0, 0.1 * (upper - lower), size=series.shape), series)\n",
    "    return series\n",
    "\n",
    "# Apply the function to each relevant column\n",
    "for column in ['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']:\n",
    "    combined_df[column] = cap_outliers(combined_df[column].values, lower_bound[column], upper_bound[column])\n",
    "\n",
    "# Check the modified DataFrame for outliers\n",
    "print(\"Outlier values have been capped and modified.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcYBj57gWu66"
   },
   "source": [
    "Checking for outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "8es1E14VWka5",
    "outputId": "3fe22c47-bbec-413c-c3b0-480e2a7cd616"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create box plots for each sensor\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(y=combined_df['bvp_mean'])\n",
    "plt.title('BVP Mean')\n",
    "plt.ylabel('BVP Values')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(y=combined_df['eda_mean'])\n",
    "plt.title('EDA Mean')\n",
    "plt.ylabel('EDA Values')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(y=combined_df['temperature_mean'])\n",
    "plt.title('Temperature Mean')\n",
    "plt.ylabel('Temperature Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-m8QkPWkGP2"
   },
   "source": [
    "checking for outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "18jITMeNNC7n",
    "outputId": "a17184a2-cfc3-4bf5-cf61-d39bbe8657cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers detected in the data:\n",
      "       bvp_mean  bvp_std  bvp_max  eda_mean  eda_std  eda_max  \\\n",
      "0           NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "1           NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "2           NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "3           NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "4           NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "...         ...      ...      ...       ...      ...      ...   \n",
      "69482       NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "69483       NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "69484       NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "69485       NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "69486       NaN      NaN      NaN       NaN      NaN      NaN   \n",
      "\n",
      "       temperature_mean  temperature_std  temperature_max  Labels  \n",
      "0                   NaN              NaN              NaN     NaN  \n",
      "1                   NaN              NaN              NaN     NaN  \n",
      "2                   NaN              NaN              NaN     NaN  \n",
      "3                   NaN              NaN              NaN     NaN  \n",
      "4                   NaN              NaN              NaN     NaN  \n",
      "...                 ...              ...              ...     ...  \n",
      "69482               NaN              NaN              NaN     NaN  \n",
      "69483               NaN              NaN              NaN     NaN  \n",
      "69484               NaN              NaN              NaN     NaN  \n",
      "69485               NaN              NaN              NaN     NaN  \n",
      "69486               NaN              NaN              NaN     NaN  \n",
      "\n",
      "[69487 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 69487,\n  \"fields\": [\n    {\n      \"column\": \"bvp_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09538415383045362,\n        \"min\": 0.2665769513655376,\n        \"max\": 0.7790145878493175,\n        \"num_unique_values\": 66538,\n        \"samples\": [\n          0.5636162840587161,\n          0.4405081178259245,\n          0.5655648699630852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bvp_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0436959339343101,\n        \"min\": 0.0,\n        \"max\": 0.1506064481739877,\n        \"num_unique_values\": 69448,\n        \"samples\": [\n          0.008561880464772674,\n          0.009860335704357369,\n          0.000769709214782214\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bvp_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09190552092262315,\n        \"min\": 0.23698222679200942,\n        \"max\": 0.7544374146997572,\n        \"num_unique_values\": 56652,\n        \"samples\": [\n          0.5853188929001203,\n          0.6694146592244419,\n          0.43556233350063706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19813074141939369,\n        \"min\": 0.0,\n        \"max\": 0.6770639826435535,\n        \"num_unique_values\": 52165,\n        \"samples\": [\n          0.18950471255617082,\n          0.0887365385985771,\n          0.6648120269159807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010766220956684454,\n        \"min\": 0.0,\n        \"max\": 0.036020439186405684,\n        \"num_unique_values\": 38372,\n        \"samples\": [\n          0.02300087117600958,\n          0.03322149858182469,\n          0.003716589299666886\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eda_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19880689919617983,\n        \"min\": 0.0,\n        \"max\": 0.6779838694085456,\n        \"num_unique_values\": 25130,\n        \"samples\": [\n          0.3180566724673489,\n          0.4399602195521908,\n          0.21515576655031818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2985404539244433,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 12567,\n        \"samples\": [\n          0.9380902413431276,\n          0.922413793103452,\n          0.8250128667009786\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16892919782265697,\n        \"min\": 0.0,\n        \"max\": 0.7142643262928272,\n        \"num_unique_values\": 705,\n        \"samples\": [\n          0.233284737407898,\n          0.16666666666668645,\n          0.6044592344641307\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2990412125906564,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2147,\n        \"samples\": [\n          0.3436293436293436,\n          0.14285714285714235,\n          0.9343629343629356\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "combined_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b67d624d-b54e-4f71-8651-0b94861603de\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bvp_mean</th>\n",
       "      <th>bvp_std</th>\n",
       "      <th>bvp_max</th>\n",
       "      <th>eda_mean</th>\n",
       "      <th>eda_std</th>\n",
       "      <th>eda_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>temperature_std</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432751</td>\n",
       "      <td>0.081647</td>\n",
       "      <td>0.403546</td>\n",
       "      <td>0.611997</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.649919</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.080188</td>\n",
       "      <td>0.452608</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>0.623526</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509877</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.466198</td>\n",
       "      <td>0.629618</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.601749</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511898</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>0.630495</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>0.595626</td>\n",
       "      <td>0.853070</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.851648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511151</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.465021</td>\n",
       "      <td>0.605312</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.638406</td>\n",
       "      <td>0.849781</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.851648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b67d624d-b54e-4f71-8651-0b94861603de')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b67d624d-b54e-4f71-8651-0b94861603de button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b67d624d-b54e-4f71-8651-0b94861603de');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6cf0fe14-6cf8-428b-9bb8-9dca925cd68e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cf0fe14-6cf8-428b-9bb8-9dca925cd68e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6cf0fe14-6cf8-428b-9bb8-9dca925cd68e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
       "0  0.432751  0.081647  0.403546  0.611997  0.035060  0.649919   \n",
       "1  0.483221  0.080188  0.452608  0.568807  0.035094  0.623526   \n",
       "2  0.509877  0.018219  0.466198  0.629618  0.034659  0.601749   \n",
       "3  0.511898  0.001696  0.465986  0.630495  0.033288  0.595626   \n",
       "4  0.511151  0.001481  0.465021  0.605312  0.034211  0.638406   \n",
       "\n",
       "   temperature_mean  temperature_std  temperature_max  Labels  \n",
       "0          0.848684            0.000         0.846154       0  \n",
       "1          0.848684            0.000         0.846154       0  \n",
       "2          0.848684            0.000         0.846154       0  \n",
       "3          0.853070            0.125         0.851648       0  \n",
       "4          0.849781            0.125         0.851648       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the first and third quartiles (Q1 and Q3)\n",
    "Q1 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.25)\n",
    "Q3 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper whiskers\n",
    "lower_whisker = Q1 - 1.5 * IQR\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = combined_df[\n",
    "    (combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']] < lower_whisker) |\n",
    "    (combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max', 'temperature_mean', 'temperature_std', 'temperature_max']] > upper_whisker)\n",
    "]\n",
    "\n",
    "# Display the outliers\n",
    "print(\"Outliers detected in the data:\")\n",
    "print(outliers)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC4nke5FNpse"
   },
   "source": [
    "Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-zsFXi1Nobg",
    "outputId": "ce133852-e796-40c8-a647-31d924dc65b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "Labels              0\n",
      "dtype: int64\n",
      "\n",
      "Data Types in Combined DataFrame:\n",
      " bvp_mean            float64\n",
      "bvp_std             float64\n",
      "bvp_max             float64\n",
      "eda_mean            float64\n",
      "eda_std             float64\n",
      "eda_max             float64\n",
      "temperature_mean    float64\n",
      "temperature_std     float64\n",
      "temperature_max     float64\n",
      "Labels                int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "            bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.522082      0.045741      0.496342      0.221722      0.012041   \n",
      "std        0.095384      0.043696      0.091906      0.198131      0.010766   \n",
      "min        0.266577      0.000000      0.236982      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        0.779015      0.150606      0.754437      0.677064      0.036020   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \\\n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000   \n",
      "mean       0.213621          0.576014         0.163314         0.575788   \n",
      "std        0.198807          0.298540         0.168929         0.299041   \n",
      "min        0.000000          0.000000         0.000000         0.000000   \n",
      "25%        0.061389          0.310987         0.000000         0.308880   \n",
      "50%        0.136029          0.632216         0.163299         0.631579   \n",
      "75%        0.308031          0.846154         0.285714         0.846154   \n",
      "max        0.677984          1.000000         0.714264         1.000000   \n",
      "\n",
      "             Labels  \n",
      "count  69487.000000  \n",
      "mean       0.545267  \n",
      "std        0.497950  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Label Distribution:\n",
      " Labels\n",
      "1    37889\n",
      "0    31598\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outliers in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = combined_df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
    "\n",
    "# Check data types of each column\n",
    "data_types = combined_df.dtypes\n",
    "print(\"\\nData Types in Combined DataFrame:\\n\", data_types)\n",
    "\n",
    "# Get summary statistics for the numeric columns\n",
    "summary_statistics = combined_df.describe()\n",
    "print(\"\\nSummary Statistics:\\n\", summary_statistics)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = combined_df.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows)\n",
    "\n",
    "# Check label distribution\n",
    "label_distribution = combined_df['Labels'].value_counts()\n",
    "print(\"\\nLabel Distribution:\\n\", label_distribution)\n",
    "\n",
    "# Check for outliers using Interquartile Range (IQR) for relevant columns\n",
    "Q1 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                  'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.25)\n",
    "Q3 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                  'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine outliers based on the IQR\n",
    "outlier_condition = ((combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean',\n",
    "                                     'eda_std', 'eda_max', 'temperature_mean',\n",
    "                                     'temperature_std', 'temperature_max']] < (Q1 - 1.5 * IQR)) |\n",
    "                     (combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean',\n",
    "                                     'eda_std', 'eda_max', 'temperature_mean',\n",
    "                                     'temperature_std', 'temperature_max']] > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "outliers = outlier_condition.sum()\n",
    "print(\"\\nOutliers in Each Column:\\n\", outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3mmBunNf2uK",
    "outputId": "6e6e013f-017e-4862-82b2-7069b8756455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "Labels              0\n",
      "dtype: int64\n",
      "\n",
      "Data Types in Combined DataFrame:\n",
      " bvp_mean            float64\n",
      "bvp_std             float64\n",
      "bvp_max             float64\n",
      "eda_mean            float64\n",
      "eda_std             float64\n",
      "eda_max             float64\n",
      "temperature_mean    float64\n",
      "temperature_std     float64\n",
      "temperature_max     float64\n",
      "Labels                int64\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "            bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.522082      0.045741      0.496342      0.221722      0.012041   \n",
      "std        0.095384      0.043696      0.091906      0.198131      0.010766   \n",
      "min        0.266577      0.000000      0.236982      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        0.779015      0.150606      0.754437      0.677064      0.036020   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \\\n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000   \n",
      "mean       0.213621          0.576014         0.163314         0.575788   \n",
      "std        0.198807          0.298540         0.168929         0.299041   \n",
      "min        0.000000          0.000000         0.000000         0.000000   \n",
      "25%        0.061389          0.310987         0.000000         0.308880   \n",
      "50%        0.136029          0.632216         0.163299         0.631579   \n",
      "75%        0.308031          0.846154         0.285714         0.846154   \n",
      "max        0.677984          1.000000         0.714264         1.000000   \n",
      "\n",
      "             Labels  \n",
      "count  69487.000000  \n",
      "mean       0.545267  \n",
      "std        0.497950  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Label Distribution:\n",
      " Labels\n",
      "1    37889\n",
      "0    31598\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Outliers in Each Column:\n",
      " bvp_mean            0\n",
      "bvp_std             0\n",
      "bvp_max             0\n",
      "eda_mean            0\n",
      "eda_std             0\n",
      "eda_max             0\n",
      "temperature_mean    0\n",
      "temperature_std     0\n",
      "temperature_max     0\n",
      "dtype: int64\n",
      "\n",
      "Correlation Matrix:\n",
      "                   bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "bvp_mean          1.000000 -0.233879  0.963547  0.176986  0.125593  0.186693   \n",
      "bvp_std          -0.233879  1.000000 -0.090269 -0.061079 -0.027568 -0.074500   \n",
      "bvp_max           0.963547 -0.090269  1.000000  0.177283  0.109720  0.180574   \n",
      "eda_mean          0.176986 -0.061079  0.177283  1.000000  0.525638  0.992904   \n",
      "eda_std           0.125593 -0.027568  0.109720  0.525638  1.000000  0.543242   \n",
      "eda_max           0.186693 -0.074500  0.180574  0.992904  0.543242  1.000000   \n",
      "temperature_mean -0.002089  0.035590 -0.001694 -0.002861  0.063894 -0.001145   \n",
      "temperature_std  -0.004764  0.004511  0.001297 -0.021689  0.016396 -0.020827   \n",
      "temperature_max  -0.001362  0.036046 -0.001283 -0.002892  0.064369 -0.001180   \n",
      "Labels           -0.001364 -0.001814  0.008466 -0.035922 -0.123558 -0.040081   \n",
      "\n",
      "                  temperature_mean  temperature_std  temperature_max    Labels  \n",
      "bvp_mean                 -0.002089        -0.004764        -0.001362 -0.001364  \n",
      "bvp_std                   0.035590         0.004511         0.036046 -0.001814  \n",
      "bvp_max                  -0.001694         0.001297        -0.001283  0.008466  \n",
      "eda_mean                 -0.002861        -0.021689        -0.002892 -0.035922  \n",
      "eda_std                   0.063894         0.016396         0.064369 -0.123558  \n",
      "eda_max                  -0.001145        -0.020827        -0.001180 -0.040081  \n",
      "temperature_mean          1.000000        -0.012595         0.999920  0.166520  \n",
      "temperature_std          -0.012595         1.000000        -0.004065 -0.018457  \n",
      "temperature_max           0.999920        -0.004065         1.000000  0.166101  \n",
      "Labels                    0.166520        -0.018457         0.166101  1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = combined_df.isnull().sum()\n",
    "print(\"Missing Values in Each Column:\\n\", missing_values)\n",
    "\n",
    "# Check data types of each column\n",
    "data_types = combined_df.dtypes\n",
    "print(\"\\nData Types in Combined DataFrame:\\n\", data_types)\n",
    "\n",
    "# Get summary statistics for the numeric columns\n",
    "summary_statistics = combined_df.describe()\n",
    "print(\"\\nSummary Statistics:\\n\", summary_statistics)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = combined_df.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows)\n",
    "\n",
    "# Check label distribution\n",
    "label_distribution = combined_df['Labels'].value_counts()\n",
    "print(\"\\nLabel Distribution:\\n\", label_distribution)\n",
    "\n",
    "# Check for outliers using Interquartile Range (IQR)\n",
    "Q1 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                  'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.25)\n",
    "Q3 = combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                  'temperature_mean', 'temperature_std', 'temperature_max']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outlier_condition = ((combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                                     'temperature_mean', 'temperature_std', 'temperature_max']] < (Q1 - 1.5 * IQR)) |\n",
    "                     (combined_df[['bvp_mean', 'bvp_std', 'bvp_max', 'eda_mean', 'eda_std', 'eda_max',\n",
    "                                     'temperature_mean', 'temperature_std', 'temperature_max']] > (Q3 + 1.5 * IQR)))\n",
    "outliers = outlier_condition.sum()\n",
    "print(\"\\nOutliers in Each Column:\\n\", outliers)\n",
    "\n",
    "# Check correlations among features\n",
    "correlation_matrix = combined_df.corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIgPayajsQGM"
   },
   "source": [
    "checking if their is much difference between 0 label and 1 label data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24lbnDXHhMkz",
    "outputId": "57dcd2c3-4f53-464f-8ef1-058f81039765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Analysis Results:\n",
      "                  t-test p-value  Mann-Whitney U p-value\n",
      "bvp_mean            7.187652e-01            1.013350e-01\n",
      "eda_mean            1.253196e-21            4.758661e-87\n",
      "temperature_mean    0.000000e+00            0.000000e+00\n",
      "\n",
      "Feature: bvp_mean\n",
      "   No significant difference between label 0 and label 1 (p-values: t-test=0.7188, Mann-Whitney U=0.1013)\n",
      "\n",
      "Feature: eda_mean\n",
      "   Significant difference between label 0 and label 1 (p-values: t-test=0.0000, Mann-Whitney U=0.0000)\n",
      "\n",
      "Feature: temperature_mean\n",
      "   Significant difference between label 0 and label 1 (p-values: t-test=0.0000, Mann-Whitney U=0.0000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "# Load your data\n",
    "# Assuming your data is in a DataFrame called `data` and `label` is the column with labels 0 and 1\n",
    "# data = pd.read_csv('your_data.csv')  # Uncomment and load your data here\n",
    "\n",
    "# List of features to compare\n",
    "features = ['bvp_mean', 'eda_mean', 'temperature_mean']  # Add all relevant features here\n",
    "\n",
    "# Separate data by label\n",
    "label_0_data = combined_df[combined_df['Labels'] == 0]  # Changed 'data' to 'combined_df' and 'label' to 'Labels'\n",
    "label_1_data = combined_df[combined_df['Labels'] == 1]  # Changed 'data' to 'combined_df' and 'label' to 'Labels'\n",
    "\n",
    "# Dictionary to store test results\n",
    "results = {}\n",
    "\n",
    "for feature in features:\n",
    "    # Perform t-test (assumes normal distribution)\n",
    "    t_stat, t_p_value = ttest_ind(label_0_data[feature], label_1_data[feature], equal_var=False)\n",
    "\n",
    "    # Perform Mann-Whitney U test (non-parametric)\n",
    "    mw_stat, mw_p_value = mannwhitneyu(label_0_data[feature], label_1_data[feature])\n",
    "\n",
    "    # Save results for each feature\n",
    "    results[feature] = {\n",
    "        't-test p-value': t_p_value,\n",
    "        'Mann-Whitney U p-value': mw_p_value\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Statistical Analysis Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Interpretation\n",
    "for feature in results:\n",
    "    t_p_value = results[feature]['t-test p-value']\n",
    "    mw_p_value = results[feature]['Mann-Whitney U p-value']\n",
    "\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    if t_p_value < 0.05 or mw_p_value < 0.05:\n",
    "        print(f\"   Significant difference between label 0 and label 1 (p-values: t-test={t_p_value:.4f}, Mann-Whitney U={mw_p_value:.4f})\")\n",
    "    else:\n",
    "        print(f\"   No significant difference between label 0 and label 1 (p-values: t-test={t_p_value:.4f}, Mann-Whitney U={mw_p_value:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HTQ4_M6x91j"
   },
   "source": [
    "MODEL BUILDING AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "ny70VCq2Znjl",
    "outputId": "3b7d4a6d-7b6f-4108-fe2a-053ee425899e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_48    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_49    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_50    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_48             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_49             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_50             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_12            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ activation_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_51    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv1d_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_51             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ activation_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ activation_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span> │ activation_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_52    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_53    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_54    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_52             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_53             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_54             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,624</span> │ activation_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_13            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ activation_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_55    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv1d_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_55             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">123,008</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_56    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_57    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_58    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_56             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_57             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_58             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">74,112</span> │ activation_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_14            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ activation_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_59    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ conv1d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_59             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,320</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,896</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">61,472</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_60    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_61    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_62    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv1d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_60             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_61             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_62             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,960</span> │ activation_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_15            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ activation_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_63    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ conv1d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                           │                        │                │ batch_normalization_6… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_63             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling1d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ global_average_poolin… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_48 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_49 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m320\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_50 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m512\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_48    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_49    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_50    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_48             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_49             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_50             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_51 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │            \u001b[38;5;34m384\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_12            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ activation_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ activation_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_51    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │            \u001b[38;5;34m384\u001b[0m │ conv1d_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_51             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_52 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m6,208\u001b[0m │ activation_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_53 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m18,496\u001b[0m │ activation_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_54 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m30,784\u001b[0m │ activation_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_52    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │            \u001b[38;5;34m256\u001b[0m │ conv1d_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_53    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │            \u001b[38;5;34m256\u001b[0m │ conv1d_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_54    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │            \u001b[38;5;34m256\u001b[0m │ conv1d_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_52             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_53             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_54             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_55 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │         \u001b[38;5;34m18,624\u001b[0m │ activation_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_13            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ activation_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ activation_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_55    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │            \u001b[38;5;34m768\u001b[0m │ conv1d_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_55             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_56 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m24,704\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_57 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m73,856\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_58 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m123,008\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_56    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │            \u001b[38;5;34m512\u001b[0m │ conv1d_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_57    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │            \u001b[38;5;34m512\u001b[0m │ conv1d_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_58    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │            \u001b[38;5;34m512\u001b[0m │ conv1d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_56             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_57             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_58             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_59 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │         \u001b[38;5;34m74,112\u001b[0m │ activation_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_14            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ activation_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ activation_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_59    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │          \u001b[38;5;34m1,536\u001b[0m │ conv1d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                           │                        │                │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_59             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m384\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_60 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m12,320\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_61 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m36,896\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_62 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │         \u001b[38;5;34m61,472\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_60    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_61    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_62    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │            \u001b[38;5;34m128\u001b[0m │ conv1d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_60             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_61             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_62             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv1d_63 (\u001b[38;5;33mConv1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │         \u001b[38;5;34m36,960\u001b[0m │ activation_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_15            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ activation_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ activation_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_63    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │            \u001b[38;5;34m384\u001b[0m │ conv1d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                           │                        │                │ batch_normalization_6… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_63             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ global_average_pooling1d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ activation_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m12,416\u001b[0m │ global_average_poolin… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">545,665</span> (2.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m545,665\u001b[0m (2.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">542,593</span> (2.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m542,593\u001b[0m (2.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, Dense, GlobalAveragePooling1D, Dropout, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def inception_residual_block(input_tensor, filters):\n",
    "    \"\"\"\n",
    "    Inception-Residual block for the model.\n",
    "\n",
    "    Args:\n",
    "        input_tensor: Input tensor to the block.\n",
    "        filters: Number of filters for the convolutional layers.\n",
    "\n",
    "    Returns:\n",
    "        Output tensor of the block.\n",
    "    \"\"\"\n",
    "    conv1 = Conv1D(filters, 1, padding='same')(input_tensor)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "\n",
    "    conv3 = Conv1D(filters, 3, padding='same')(input_tensor)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "\n",
    "    conv5 = Conv1D(filters, 5, padding='same')(input_tensor)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    inception_output = concatenate([conv1, conv3, conv5], axis=-1)\n",
    "\n",
    "    shortcut = Conv1D(filters * 3, 1, padding='same')(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Add()([inception_output, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_resnet_inception_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds the ResNet-Inception model.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Shape of the input data.\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for filters in [32, 64, 128, 32]:\n",
    "        x = inception_residual_block(x, filters)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def pad_and_reshape(data, timesteps=4):\n",
    "    \"\"\"\n",
    "    Pads and reshapes the input data for the Conv1D layer.\n",
    "\n",
    "    Args:\n",
    "        data: Input data to be padded and reshaped.\n",
    "        timesteps: Desired number of timesteps.\n",
    "\n",
    "    Returns:\n",
    "        Padded and reshaped data.\n",
    "    \"\"\"\n",
    "    padding_needed = timesteps - data.shape[1] % timesteps\n",
    "    if padding_needed != 0:\n",
    "        padding_shape = (data.shape[0], padding_needed)\n",
    "        padding = np.zeros(padding_shape)\n",
    "        data_padded = np.concatenate([data, padding], axis=1)\n",
    "    else:\n",
    "        data_padded = data\n",
    "    return data_padded.reshape(data_padded.shape[0], timesteps, -1)\n",
    "\n",
    "\n",
    "# Assuming 'combined_df' is your DataFrame\n",
    "X = combined_df.drop(columns=['Labels']).values\n",
    "y = combined_df['Labels'].values\n",
    "\n",
    "# Split data\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(X_train_raw, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pad and reshape data (timestep is now 4)\n",
    "X_train = pad_and_reshape(X_train_raw, timesteps=4)\n",
    "X_test = pad_and_reshape(X_test_raw, timesteps=4)\n",
    "X_val = pad_and_reshape(X_val_raw, timesteps=4)\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = X_train.shape[1:]\n",
    "model = build_resnet_inception_model(input_shape)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary to confirm changes\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNHhbjwKcR5M",
    "outputId": "b4d61b67-ab87-4c4a-d4d2-4bd7d87f70e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 25ms/step - accuracy: 0.5688 - loss: 0.6956 - val_accuracy: 0.6096 - val_loss: 0.6508 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.6229 - loss: 0.6477 - val_accuracy: 0.6622 - val_loss: 0.6203 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.6489 - loss: 0.6283 - val_accuracy: 0.6707 - val_loss: 0.6078 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.6655 - loss: 0.6175 - val_accuracy: 0.6838 - val_loss: 0.6046 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.6781 - loss: 0.6035 - val_accuracy: 0.7020 - val_loss: 0.5733 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.6910 - loss: 0.5867 - val_accuracy: 0.7043 - val_loss: 0.5659 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.6988 - loss: 0.5788 - val_accuracy: 0.7129 - val_loss: 0.5626 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7076 - loss: 0.5668 - val_accuracy: 0.7108 - val_loss: 0.5531 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.7099 - loss: 0.5583 - val_accuracy: 0.7016 - val_loss: 0.5518 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7172 - loss: 0.5522 - val_accuracy: 0.7280 - val_loss: 0.5299 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7281 - loss: 0.5388 - val_accuracy: 0.7191 - val_loss: 0.5279 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 25ms/step - accuracy: 0.7330 - loss: 0.5259 - val_accuracy: 0.7396 - val_loss: 0.5092 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7382 - loss: 0.5195 - val_accuracy: 0.7165 - val_loss: 0.5362 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7463 - loss: 0.5095 - val_accuracy: 0.7343 - val_loss: 0.5088 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - accuracy: 0.7483 - loss: 0.5014 - val_accuracy: 0.7477 - val_loss: 0.5110 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.7546 - loss: 0.4963 - val_accuracy: 0.7616 - val_loss: 0.4853 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 25ms/step - accuracy: 0.7622 - loss: 0.4842 - val_accuracy: 0.7786 - val_loss: 0.4672 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.7685 - loss: 0.4777 - val_accuracy: 0.7614 - val_loss: 0.4812 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 25ms/step - accuracy: 0.7715 - loss: 0.4699 - val_accuracy: 0.7684 - val_loss: 0.4609 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7752 - loss: 0.4634 - val_accuracy: 0.7912 - val_loss: 0.4554 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7817 - loss: 0.4511 - val_accuracy: 0.7881 - val_loss: 0.4587 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7864 - loss: 0.4484 - val_accuracy: 0.6926 - val_loss: 0.6177 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7866 - loss: 0.4461 - val_accuracy: 0.7914 - val_loss: 0.4349 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.7914 - loss: 0.4388 - val_accuracy: 0.7948 - val_loss: 0.4284 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7949 - loss: 0.4327 - val_accuracy: 0.7923 - val_loss: 0.4237 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 25ms/step - accuracy: 0.7971 - loss: 0.4221 - val_accuracy: 0.7196 - val_loss: 0.5467 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7964 - loss: 0.4207 - val_accuracy: 0.6967 - val_loss: 0.6156 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8029 - loss: 0.4178 - val_accuracy: 0.7954 - val_loss: 0.4208 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8097 - loss: 0.4067 - val_accuracy: 0.7113 - val_loss: 0.5661 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8065 - loss: 0.4077 - val_accuracy: 0.7661 - val_loss: 0.4758 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8139 - loss: 0.3999 - val_accuracy: 0.7724 - val_loss: 0.4486 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.8246 - loss: 0.3785 - val_accuracy: 0.8142 - val_loss: 0.3835 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 24ms/step - accuracy: 0.8285 - loss: 0.3635 - val_accuracy: 0.8277 - val_loss: 0.3699 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8286 - loss: 0.3664 - val_accuracy: 0.8279 - val_loss: 0.3709 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8331 - loss: 0.3573 - val_accuracy: 0.8256 - val_loss: 0.3800 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.8344 - loss: 0.3570 - val_accuracy: 0.8050 - val_loss: 0.4064 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8391 - loss: 0.3476 - val_accuracy: 0.8445 - val_loss: 0.3459 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8423 - loss: 0.3373 - val_accuracy: 0.8433 - val_loss: 0.3469 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8476 - loss: 0.3341 - val_accuracy: 0.8430 - val_loss: 0.3463 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8451 - loss: 0.3323 - val_accuracy: 0.8419 - val_loss: 0.3567 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 24ms/step - accuracy: 0.8533 - loss: 0.3215 - val_accuracy: 0.8510 - val_loss: 0.3367 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8510 - loss: 0.3192 - val_accuracy: 0.8493 - val_loss: 0.3372 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8526 - loss: 0.3194 - val_accuracy: 0.8510 - val_loss: 0.3311 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8555 - loss: 0.3167 - val_accuracy: 0.8527 - val_loss: 0.3321 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8556 - loss: 0.3119 - val_accuracy: 0.8527 - val_loss: 0.3375 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8569 - loss: 0.3086 - val_accuracy: 0.8500 - val_loss: 0.3318 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8604 - loss: 0.3056 - val_accuracy: 0.8547 - val_loss: 0.3301 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8575 - loss: 0.3046 - val_accuracy: 0.8534 - val_loss: 0.3291 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.8568 - loss: 0.3101 - val_accuracy: 0.8543 - val_loss: 0.3291 - learning_rate: 6.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m1390/1390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8625 - loss: 0.2989 - val_accuracy: 0.8559 - val_loss: 0.3271 - learning_rate: 6.2500e-05\n",
      "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 0.3164\n",
      "Test Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5trW-JQ61M2v"
   },
   "source": [
    "DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdwxca_Gqxvu",
    "outputId": "856d204e-9f0f-438f-d06c-f9dd584cafa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            bvp_mean        bvp_std        bvp_max       eda_mean  \\\n",
      "count  277948.000000  277948.000000  277948.000000  277948.000000   \n",
      "mean        0.522096       0.045869       0.496345       0.221743   \n",
      "std         0.095921       0.043857       0.092033       0.198178   \n",
      "min         0.247315       0.000000       0.228107       0.000000   \n",
      "25%         0.458066       0.012036       0.430800       0.066415   \n",
      "50%         0.516084       0.029361       0.498298       0.159111   \n",
      "75%         0.587751       0.067351       0.560375       0.311163   \n",
      "max         0.798432       0.160433       0.763498       0.686604   \n",
      "\n",
      "             eda_std        eda_max  temperature_mean  temperature_std  \\\n",
      "count  277948.000000  277948.000000     277948.000000    277948.000000   \n",
      "mean        0.012107       0.213622          0.576016         0.164124   \n",
      "std         0.010972       0.198814          0.298576         0.168208   \n",
      "min         0.000000       0.000000          0.000000         0.000000   \n",
      "25%         0.003992       0.061476          0.312139         0.000000   \n",
      "50%         0.008044       0.136288          0.631792         0.162091   \n",
      "75%         0.017106       0.308083          0.846229         0.278191   \n",
      "max         0.041005       0.682705          1.009767         0.722063   \n",
      "\n",
      "       temperature_max         Labels  \n",
      "count    277948.000000  277948.000000  \n",
      "mean          0.575795       0.545267  \n",
      "std           0.299069       0.497948  \n",
      "min           0.000000       0.000000  \n",
      "25%           0.311878       0.000000  \n",
      "50%           0.631717       1.000000  \n",
      "75%           0.846154       1.000000  \n",
      "max           1.009991       1.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def augment_data(df, noise_levels, num_augmentations=3):\n",
    "    augmented_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for _ in range(num_augmentations):\n",
    "            # Copy the original row to create an augmented version\n",
    "            augmented_row = row.copy()\n",
    "            for column in noise_levels.keys():\n",
    "                # Add random noise within the specified range\n",
    "                noise = np.random.uniform(-noise_levels[column], noise_levels[column])\n",
    "                augmented_row[column] += noise\n",
    "\n",
    "                # Ensure the data remains within the specified range\n",
    "                augmented_row[column] = max(0, augmented_row[column])  # Assuming all values should be >= 0\n",
    "\n",
    "            augmented_data.append(augmented_row)\n",
    "\n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "# Assuming combined_df is your original DataFrame\n",
    "noise_levels = {\n",
    "    'bvp_mean': 0.02,\n",
    "    'bvp_std': 0.01,\n",
    "    'bvp_max': 0.01,\n",
    "    'eda_mean': 0.01,\n",
    "    'eda_std': 0.005,\n",
    "    'eda_max': 0.005,\n",
    "    'temperature_mean': 0.01,\n",
    "    'temperature_std': 0.01,\n",
    "    'temperature_max': 0.01,\n",
    "}\n",
    "\n",
    "# Generate augmented data with 3 unique augmentations per original data point\n",
    "augmented_df = augment_data(combined_df, noise_levels, num_augmentations=3)\n",
    "\n",
    "# Concatenate the original and augmented data\n",
    "combined_augmented_df = pd.concat([combined_df, augmented_df], ignore_index=True)\n",
    "\n",
    "# Check the statistics again\n",
    "print(combined_augmented_df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vH_6NhTyTpAl",
    "outputId": "b876149e-ed01-4dfd-e693-b21b9be058e0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "combined_augmented_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d030b3cd-d7f9-4b00-9fc0-e65b680951a4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bvp_mean</th>\n",
       "      <th>bvp_std</th>\n",
       "      <th>bvp_max</th>\n",
       "      <th>eda_mean</th>\n",
       "      <th>eda_std</th>\n",
       "      <th>eda_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>temperature_std</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.432751</td>\n",
       "      <td>0.081647</td>\n",
       "      <td>0.403546</td>\n",
       "      <td>0.611997</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.649919</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.080188</td>\n",
       "      <td>0.452608</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.035094</td>\n",
       "      <td>0.623526</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509877</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.466198</td>\n",
       "      <td>0.629618</td>\n",
       "      <td>0.034659</td>\n",
       "      <td>0.601749</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511898</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>0.630495</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>0.595626</td>\n",
       "      <td>0.853070</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.851648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.511151</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.465021</td>\n",
       "      <td>0.605312</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.638406</td>\n",
       "      <td>0.849781</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.851648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d030b3cd-d7f9-4b00-9fc0-e65b680951a4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d030b3cd-d7f9-4b00-9fc0-e65b680951a4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d030b3cd-d7f9-4b00-9fc0-e65b680951a4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8bfe13c3-638d-425b-ac6e-7fba5fc74f9c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bfe13c3-638d-425b-ac6e-7fba5fc74f9c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8bfe13c3-638d-425b-ac6e-7fba5fc74f9c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
       "0  0.432751  0.081647  0.403546  0.611997  0.035060  0.649919   \n",
       "1  0.483221  0.080188  0.452608  0.568807  0.035094  0.623526   \n",
       "2  0.509877  0.018219  0.466198  0.629618  0.034659  0.601749   \n",
       "3  0.511898  0.001696  0.465986  0.630495  0.033288  0.595626   \n",
       "4  0.511151  0.001481  0.465021  0.605312  0.034211  0.638406   \n",
       "\n",
       "   temperature_mean  temperature_std  temperature_max  Labels  \n",
       "0          0.848684            0.000         0.846154     0.0  \n",
       "1          0.848684            0.000         0.846154     0.0  \n",
       "2          0.848684            0.000         0.846154     0.0  \n",
       "3          0.853070            0.125         0.851648     0.0  \n",
       "4          0.849781            0.125         0.851648     0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_augmented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k362486l1Qm0"
   },
   "source": [
    "CHECK AUGMENTED DATA WITH ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lnyd-9kerKIC",
    "outputId": "4124b2b3-d9e4-4ece-ece4-792800079652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "           bvp_mean       bvp_std       bvp_max      eda_mean       eda_std  \\\n",
      "count  69487.000000  69487.000000  69487.000000  69487.000000  69487.000000   \n",
      "mean       0.522082      0.045741      0.496342      0.221722      0.012041   \n",
      "std        0.095384      0.043696      0.091906      0.198131      0.010766   \n",
      "min        0.266577      0.000000      0.236982      0.000000      0.000000   \n",
      "25%        0.458773      0.011517      0.431044      0.066755      0.004030   \n",
      "50%        0.516266      0.028862      0.498660      0.159124      0.007525   \n",
      "75%        0.586911      0.067154      0.560425      0.310885      0.016826   \n",
      "max        0.779015      0.150606      0.754437      0.677064      0.036020   \n",
      "\n",
      "            eda_max  temperature_mean  temperature_std  temperature_max  \\\n",
      "count  69487.000000      69487.000000     69487.000000     69487.000000   \n",
      "mean       0.213621          0.576014         0.163314         0.575788   \n",
      "std        0.198807          0.298540         0.168929         0.299041   \n",
      "min        0.000000          0.000000         0.000000         0.000000   \n",
      "25%        0.061389          0.310987         0.000000         0.308880   \n",
      "50%        0.136029          0.632216         0.163299         0.631579   \n",
      "75%        0.308031          0.846154         0.285714         0.846154   \n",
      "max        0.677984          1.000000         0.714264         1.000000   \n",
      "\n",
      "             Labels  \n",
      "count  69487.000000  \n",
      "mean       0.545267  \n",
      "std        0.497950  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        1.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "Augmented Data Statistics:\n",
      "            bvp_mean        bvp_std        bvp_max       eda_mean  \\\n",
      "count  277948.000000  277948.000000  277948.000000  277948.000000   \n",
      "mean        0.522096       0.045869       0.496345       0.221743   \n",
      "std         0.095921       0.043857       0.092033       0.198178   \n",
      "min         0.247315       0.000000       0.228107       0.000000   \n",
      "25%         0.458066       0.012036       0.430800       0.066415   \n",
      "50%         0.516084       0.029361       0.498298       0.159111   \n",
      "75%         0.587751       0.067351       0.560375       0.311163   \n",
      "max         0.798432       0.160433       0.763498       0.686604   \n",
      "\n",
      "             eda_std        eda_max  temperature_mean  temperature_std  \\\n",
      "count  277948.000000  277948.000000     277948.000000    277948.000000   \n",
      "mean        0.012107       0.213622          0.576016         0.164124   \n",
      "std         0.010972       0.198814          0.298576         0.168208   \n",
      "min         0.000000       0.000000          0.000000         0.000000   \n",
      "25%         0.003992       0.061476          0.312139         0.000000   \n",
      "50%         0.008044       0.136288          0.631792         0.162091   \n",
      "75%         0.017106       0.308083          0.846229         0.278191   \n",
      "max         0.041005       0.682705          1.009767         0.722063   \n",
      "\n",
      "       temperature_max         Labels  \n",
      "count    277948.000000  277948.000000  \n",
      "mean          0.575795       0.545267  \n",
      "std           0.299069       0.497948  \n",
      "min           0.000000       0.000000  \n",
      "25%           0.311878       0.000000  \n",
      "50%           0.631717       1.000000  \n",
      "75%           0.846154       1.000000  \n",
      "max           1.009991       1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Calculate statistical summaries for both original and augmented datasets\n",
    "original_stats = combined_df.describe()\n",
    "augmented_stats = combined_augmented_df.describe()\n",
    "\n",
    "# Print the summaries\n",
    "print(\"Original Data Statistics:\")\n",
    "print(original_stats)\n",
    "\n",
    "print(\"\\nAugmented Data Statistics:\")\n",
    "print(augmented_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMGAQha0TFXI",
    "outputId": "d86aefbb-c70b-4c4a-cbbd-3a7219989cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Number of duplicate rows in augmented data (excluding original): 0\n",
      "Label distribution in augmented data:\n",
      "Labels\n",
      "0.0    126392\n",
      "1.0    151556\n",
      "dtype: int64\n",
      "\n",
      "Min/Max values for the augmented data:\n",
      "      bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "min  0.247315  0.000000  0.228107  0.000000  0.000000  0.000000   \n",
      "max  0.798432  0.160433  0.763498  0.686604  0.041005  0.682705   \n",
      "\n",
      "     temperature_mean  temperature_std  temperature_max  Labels  \n",
      "min          0.000000         0.000000         0.000000     0.0  \n",
      "max          1.009767         0.722063         1.009991     1.0  \n",
      "Mean/Std values for the augmented data:\n",
      "       bvp_mean   bvp_std   bvp_max  eda_mean   eda_std   eda_max  \\\n",
      "mean  0.522096  0.045869  0.496345  0.221743  0.012107  0.213622   \n",
      "std   0.095921  0.043857  0.092033  0.198178  0.010972  0.198814   \n",
      "\n",
      "      temperature_mean  temperature_std  temperature_max    Labels  \n",
      "mean          0.576016         0.164124         0.575795  0.545267  \n",
      "std           0.298576         0.168208         0.299069  0.497948  \n",
      "Warning: Some augmented data points are outside the original data range.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_augmented_data_quality(augmented_df, original_df):\n",
    "    # 1. Check for exact duplicate rows\n",
    "    duplicates = augmented_df.duplicated()\n",
    "    print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
    "\n",
    "    # 2. Check if the augmented data has duplicates after excluding original data\n",
    "    unique_augmented_df = augmented_df[~augmented_df.index.isin(original_df.index)]\n",
    "    duplicates_in_augmented = unique_augmented_df.duplicated()\n",
    "    print(f\"Number of duplicate rows in augmented data (excluding original): {duplicates_in_augmented.sum()}\")\n",
    "\n",
    "    # 3. Check for duplicate label combinations\n",
    "    label_combinations = augmented_df.groupby(['Labels']).size()\n",
    "    print(f\"Label distribution in augmented data:\\n{label_combinations}\\n\")\n",
    "\n",
    "    # 4. Ensure augmented data stays within reasonable bounds (no extreme values)\n",
    "    min_max_check = augmented_df.describe().loc[['min', 'max']]\n",
    "    print(\"Min/Max values for the augmented data:\\n\", min_max_check)\n",
    "\n",
    "    # 5. Ensure that the augmented data is similar to the original (compare means and std devs)\n",
    "    augmented_mean_std = augmented_df.describe().loc[['mean', 'std']]\n",
    "    print(\"Mean/Std values for the augmented data:\\n\", augmented_mean_std)\n",
    "\n",
    "    # 6. Check if there are any extreme values outside original data range\n",
    "    if augmented_df.min().min() < original_df.min().min() or augmented_df.max().max() > original_df.max().max():\n",
    "        print(\"Warning: Some augmented data points are outside the original data range.\")\n",
    "    else:\n",
    "        print(\"All augmented data points are within the original data range.\")\n",
    "\n",
    "# Example usage\n",
    "check_augmented_data_quality(combined_augmented_df, combined_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cCA_ToI16Ke"
   },
   "source": [
    "AGAIN TRAIN MODEL WITH AUGMENTED DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxOtAIdT1VpR",
    "outputId": "b7dafe85-b0cc-41c8-ed35-ba53969f2a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 29ms/step - accuracy: 0.6346 - loss: 0.6405 - val_accuracy: 0.7114 - val_loss: 0.5418 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 30ms/step - accuracy: 0.7111 - loss: 0.5522 - val_accuracy: 0.7388 - val_loss: 0.5088 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 30ms/step - accuracy: 0.7411 - loss: 0.5082 - val_accuracy: 0.7703 - val_loss: 0.4577 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 29ms/step - accuracy: 0.7622 - loss: 0.4752 - val_accuracy: 0.7916 - val_loss: 0.4344 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - accuracy: 0.7826 - loss: 0.4462 - val_accuracy: 0.7828 - val_loss: 0.4571 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 29ms/step - accuracy: 0.7924 - loss: 0.4283 - val_accuracy: 0.8113 - val_loss: 0.4009 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - accuracy: 0.8026 - loss: 0.4133 - val_accuracy: 0.8138 - val_loss: 0.3900 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 29ms/step - accuracy: 0.8092 - loss: 0.4019 - val_accuracy: 0.8321 - val_loss: 0.3618 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 28ms/step - accuracy: 0.8176 - loss: 0.3887 - val_accuracy: 0.8370 - val_loss: 0.3530 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.8206 - loss: 0.3821 - val_accuracy: 0.8347 - val_loss: 0.3571 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.8254 - loss: 0.3739 - val_accuracy: 0.8419 - val_loss: 0.3431 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 28ms/step - accuracy: 0.8308 - loss: 0.3646 - val_accuracy: 0.8415 - val_loss: 0.3439 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 28ms/step - accuracy: 0.8346 - loss: 0.3580 - val_accuracy: 0.8380 - val_loss: 0.3483 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 29ms/step - accuracy: 0.8375 - loss: 0.3523 - val_accuracy: 0.8375 - val_loss: 0.3564 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 29ms/step - accuracy: 0.8505 - loss: 0.3256 - val_accuracy: 0.8628 - val_loss: 0.3011 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 29ms/step - accuracy: 0.8558 - loss: 0.3160 - val_accuracy: 0.8683 - val_loss: 0.2901 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 28ms/step - accuracy: 0.8601 - loss: 0.3091 - val_accuracy: 0.8695 - val_loss: 0.2917 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 29ms/step - accuracy: 0.8616 - loss: 0.3057 - val_accuracy: 0.8693 - val_loss: 0.2869 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 29ms/step - accuracy: 0.8633 - loss: 0.3028 - val_accuracy: 0.8730 - val_loss: 0.2843 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 28ms/step - accuracy: 0.8648 - loss: 0.2984 - val_accuracy: 0.8744 - val_loss: 0.2834 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - accuracy: 0.8652 - loss: 0.2955 - val_accuracy: 0.8719 - val_loss: 0.2837 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 29ms/step - accuracy: 0.8653 - loss: 0.2963 - val_accuracy: 0.8727 - val_loss: 0.2814 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 29ms/step - accuracy: 0.8708 - loss: 0.2883 - val_accuracy: 0.8785 - val_loss: 0.2748 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.8726 - loss: 0.2842 - val_accuracy: 0.8777 - val_loss: 0.2730 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 29ms/step - accuracy: 0.8719 - loss: 0.2826 - val_accuracy: 0.8770 - val_loss: 0.2761 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 29ms/step - accuracy: 0.8737 - loss: 0.2804 - val_accuracy: 0.8802 - val_loss: 0.2657 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 28ms/step - accuracy: 0.8753 - loss: 0.2773 - val_accuracy: 0.8749 - val_loss: 0.2758 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 29ms/step - accuracy: 0.8768 - loss: 0.2748 - val_accuracy: 0.8776 - val_loss: 0.2697 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 30ms/step - accuracy: 0.8781 - loss: 0.2735 - val_accuracy: 0.8853 - val_loss: 0.2585 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 29ms/step - accuracy: 0.8781 - loss: 0.2731 - val_accuracy: 0.8866 - val_loss: 0.2589 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 29ms/step - accuracy: 0.8789 - loss: 0.2706 - val_accuracy: 0.8786 - val_loss: 0.2670 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 29ms/step - accuracy: 0.8810 - loss: 0.2655 - val_accuracy: 0.8793 - val_loss: 0.2676 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.8880 - loss: 0.2525 - val_accuracy: 0.8919 - val_loss: 0.2421 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 29ms/step - accuracy: 0.8918 - loss: 0.2428 - val_accuracy: 0.8910 - val_loss: 0.2449 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 29ms/step - accuracy: 0.8925 - loss: 0.2411 - val_accuracy: 0.8943 - val_loss: 0.2406 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.8942 - loss: 0.2413 - val_accuracy: 0.8933 - val_loss: 0.2402 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 29ms/step - accuracy: 0.8934 - loss: 0.2381 - val_accuracy: 0.8919 - val_loss: 0.2428 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 28ms/step - accuracy: 0.8935 - loss: 0.2393 - val_accuracy: 0.8974 - val_loss: 0.2357 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 29ms/step - accuracy: 0.8969 - loss: 0.2324 - val_accuracy: 0.8920 - val_loss: 0.2472 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 28ms/step - accuracy: 0.8959 - loss: 0.2337 - val_accuracy: 0.8969 - val_loss: 0.2365 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 28ms/step - accuracy: 0.8963 - loss: 0.2329 - val_accuracy: 0.8973 - val_loss: 0.2368 - learning_rate: 2.5000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 28ms/step - accuracy: 0.8993 - loss: 0.2249 - val_accuracy: 0.8984 - val_loss: 0.2310 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 28ms/step - accuracy: 0.9034 - loss: 0.2180 - val_accuracy: 0.9019 - val_loss: 0.2255 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 29ms/step - accuracy: 0.9050 - loss: 0.2153 - val_accuracy: 0.9015 - val_loss: 0.2275 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 28ms/step - accuracy: 0.9035 - loss: 0.2176 - val_accuracy: 0.9030 - val_loss: 0.2256 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 28ms/step - accuracy: 0.9047 - loss: 0.2157 - val_accuracy: 0.9035 - val_loss: 0.2246 - learning_rate: 1.2500e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 28ms/step - accuracy: 0.9042 - loss: 0.2171 - val_accuracy: 0.9035 - val_loss: 0.2260 - learning_rate: 1.2500e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 28ms/step - accuracy: 0.9058 - loss: 0.2134 - val_accuracy: 0.9029 - val_loss: 0.2254 - learning_rate: 1.2500e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 28ms/step - accuracy: 0.9065 - loss: 0.2122 - val_accuracy: 0.9020 - val_loss: 0.2279 - learning_rate: 1.2500e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 28ms/step - accuracy: 0.9088 - loss: 0.2066 - val_accuracy: 0.9058 - val_loss: 0.2215 - learning_rate: 6.2500e-05\n",
      "\u001b[1m869/869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8993 - loss: 0.2292\n",
      "Test Accuracy on Augmented Data: 0.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define features and labels\n",
    "X_augmented = combined_augmented_df.drop(columns=['Labels']).values\n",
    "y_augmented = combined_augmented_df['Labels'].values\n",
    "\n",
    "# Split the augmented data\n",
    "X_train_aug, X_temp, y_train_aug, y_temp = train_test_split(X_augmented, y_augmented, test_size=0.2, random_state=42)\n",
    "X_val_aug, X_test_aug, y_val_aug, y_test_aug = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Pad and reshape the augmented data (assuming pad_and_reshape function is defined)\n",
    "X_train_aug = pad_and_reshape(X_train_aug)\n",
    "X_val_aug = pad_and_reshape(X_val_aug)\n",
    "X_test_aug = pad_and_reshape(X_test_aug)\n",
    "\n",
    "# Build and compile the model\n",
    "input_shape = X_train_aug.shape[1:]\n",
    "model = build_resnet_inception_model(input_shape)  # Ensure this function is defined\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Fit the model on the augmented data\n",
    "history_aug = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_aug, y_val_aug),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss_aug, test_accuracy_aug = model.evaluate(X_test_aug, y_test_aug)\n",
    "print(f\"Test Accuracy on Augmented Data: {test_accuracy_aug:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh3yN1NDmiNM",
    "outputId": "b02c4cbd-edb3-4239-8493-2d4fa722aab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 28ms/step - accuracy: 0.9091 - loss: 0.2055 - val_accuracy: 0.9070 - val_loss: 0.2201 - learning_rate: 6.2500e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 28ms/step - accuracy: 0.9106 - loss: 0.2033 - val_accuracy: 0.9065 - val_loss: 0.2203 - learning_rate: 6.2500e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9111 - loss: 0.2035\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 28ms/step - accuracy: 0.9111 - loss: 0.2035 - val_accuracy: 0.9066 - val_loss: 0.2204 - learning_rate: 6.2500e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m6949/6949\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 28ms/step - accuracy: 0.9108 - loss: 0.2014 - val_accuracy: 0.9071 - val_loss: 0.2205 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Early stopping: monitor validation loss, and stop after 3 epochs with no improvement\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Learning rate scheduler: Reduce the learning rate when validation loss plateaus\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "\n",
    "# Train the model with additional epochs and callbacks to prevent overfitting\n",
    "history_aug = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    epochs=15,  # Set a reasonable number of epochs for training\n",
    "    batch_size=32,  # Batch size remains the same\n",
    "    validation_data=(X_val_aug, y_val_aug),  # Use augmented validation data\n",
    "    callbacks=[early_stopping, lr_scheduler],  # Prevent overfitting with callbacks\n",
    "    verbose=1  # Show progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vij7B6WOt2iX",
    "outputId": "44b868ad-80e2-49d9-dd5f-317fc390457d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m869/869\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.2298\n",
      "Test Accuracy on Augmented Data: 0.90\n"
     ]
    }
   ],
   "source": [
    "test_loss_aug, test_accuracy_aug = model.evaluate(X_test_aug, y_test_aug)\n",
    "print(f\"Test Accuracy on Augmented Data: {test_accuracy_aug:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06TW_Wcov-xc",
    "outputId": "101d69d8-cbe3-467d-d410-57917ee88936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Sample 12293: Stressed\n",
      "Sample 2139: Stressed\n",
      "Sample 12637: Not Stressed\n",
      "Sample 9578: Stressed\n",
      "Sample 278: Stressed\n",
      "Sample 9872: Stressed\n",
      "Sample 9950: Stressed\n",
      "Sample 316: Stressed\n",
      "Sample 7435: Stressed\n",
      "Sample 8745: Stressed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select 10 random data points from the test data\n",
    "random_indices = np.random.choice(X_test.shape[0], size=10, replace=False)\n",
    "random_test_data = X_test[random_indices]\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = model.predict(random_test_data)\n",
    "\n",
    "# Convert predictions to stressed (1) or not stressed (0)\n",
    "predictions_label = (predictions > 0.5).astype(int)  # assuming binary classification\n",
    "\n",
    "# Print the results\n",
    "for i, prediction in enumerate(predictions_label):\n",
    "    status = \"Stressed\" if prediction == 1 else \"Not Stressed\"\n",
    "    print(f\"Sample {random_indices[i]+1}: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "mmdh9HWuwY1N"
   },
   "outputs": [],
   "source": [
    "# Save the model in .h5 format\n",
    "model.save('stress_detection_model_90_percent.keras')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
